# -*- coding: utf-8 -*-
"""Golf Caddy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Bn2yrmA3xqjzYSd72Dt8sD9esf2H3zK_
"""


# Setup
import pandas as pd
import numpy as np
from openai import OpenAI
import faiss
import os
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])

# Loading CSV
df = pd.read_csv("CourseData.csv")

# Convert each hole into text
def row_to_text(row):
    return f"""
    CourseName {row['Course Name']}
    Hole: {row['Hole Number']}
    Par: {row['Par']}
    Rating: {row['Handicap for that hole']}
    BackYardage: {row['Back Tee yardage']}
    MidYardage: {row['Medium Tee Yardage']}
    FrontYardage: {row['front tee yardages']}
    Description: {row['special notes about that hole']}
    """

documents = df.apply(row_to_text, axis=1).tolist()

# Create Embedding
def get_embedding(text):
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )
    return response.data[0].embedding

embeddings = [get_embedding(doc) for doc in documents]

# Store in FAISS (Vector DB)
dim = len(embeddings[0])
index = faiss.IndexFlatL2(dim)

index.add(np.array(embeddings).astype('float32'))

# Retrieval Function (RAG)
def retrieve(query, k=3):
    q_emb = np.array([get_embedding(query)]).astype('float32')
    distances, indices = index.search(q_emb, k)
    return [documents[i] for i in indices[0]]

# System Prompt
SYSTEM_PROMPT = """
You are a friendly professional golf caddy.

GOALS:
- Give concise shot by shot advice for each hole
- Adapt advice based on handicap and distance
- Think step-by-step internally, but keep output short

Rules:
- Higher handicap = safer play
- Lower handicap = more aggressive
- Always recommend a specific club 
- Keep answers short and concise
- Give step-by-step shot strategy
- Adjust advice based on handicap and distance
- Use simple reasoning (but don't over-explain)
- if user does not give the course in the prompt, ask the user to kindly clarify which course they are playing on first. 

STYLE:
- 1 short hole summary
- Then shot-by-shot plan
- No long explanations

FORMAT:
Hole summary.
First shot -
Second shot -
Third/Fourth shot -
"""

# In Context Learning
One_Hole_Example = [
    {
        "role": "user",
        "content": "I am playing hole 2 at remington parkview valley course. I am a 10 handicap and playing from the back tees. How should I approach this hole? "
    },
    {
        "role": "assistant",
        "content": """Hole 2 at Remington Parkview Valley course is a Par 5, 569 yards if you are playing from the back tees. It has a rating of 1, meaning it is the hardest hole on the course. There is a pond to the right of the hole past 150 yards. As a 10 handicap, you’re good enough to play this as a strategic three-shot hole, not a “hero Par 5.” Since it’s the #1 handicap hole at Remington Parkview Valley Golf & Country Club, your goal is smart positioning, not forcing birdie.

1) Tee shot (569 yards remaining): Use Driver - Aim left-center — pond is right past 150, so right miss is dead. Hit driver only if you can commit to that left target.
2) Second shot (294-344 yards remaining): Use a 3 wood or 4 iron (or any fairway wood and long iron) - You should have ar Lay up to a comfortable wedge distance (90–120 yards). Stay left side again — no hero shot.
Third shot(119-169 yards remaining): Use a 9 iron or pitching wedge - Aim middle of the green, not the flag. Par is a great score here — don’t force birdie. Good luck!"""
    }
]

# Add Hidden reasoning and generate answer
def answer_query(query):
    context = retrieve(query)
    context_text = "\n\n".join(context)

    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        *One_Hole_Example,
        {
            "role": "user",
            "content": f"""
Context:
{context_text}

Think step by step about:
- hole difficulty
- player skill
- distance strategy

But ONLY output the final concise answer.

Question:
{query}
""",
        },
    ]

    response = client.chat.completions.create(
        model="gpt-4o-mini", messages=messages, temperature=0.4
    )

    output = response.choices[0].message.content
    return output

# git status
# git add .
# git commit -m ''
# git push
# 